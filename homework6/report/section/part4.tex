\section{Regularized Wiener Filter and Leaky LMS}\label{sec:p4}

\begin{enumerate}[(a)]
\item We want to solve $w$ for \[R_x w = R_{xd}\]
If $R_x$ is singular, it is not invertible and therefore LMS will diverge.

\item To avoid singularity, we can add a regularization term to the cost function, i.e.
\begin{align*}
	C(w) 
	&= \Expect{\abs{e[n]}^2} + \lambda\norm{w}^2 \\
	&= w^\top R_x w - 2 w^\top R_{xd} + \gamma_d + \lambda w^\top w \\
	&= w^\top (R_x + \lambda I) w - 2 w^\top R_{xd} + \alpha
\end{align*}
Therefore, the gradient is
\[\nabla C(w) = 2\left((R_x + \lambda I)w - R_{xd}\right)\]
and 
\[ (R_x + \lambda I)w = R_{xd} \Rightarrow w_{opt} = (R_x + \lambda I)^{-1} R_{xd}\]

\item If $R_x$ is singular, its eigenvalues are zero. By adding $\lambda$, we can shift the eigenvalues to $\lambda$ to have it invertible, where the inverse is unique.

\item For leaky LMS, we simply add the regularization term to the cost function, i.e. 
\begin{align*}
	C_{reg}(w) &= C(w) + \lambda \norm{w}^2 \\
	\Rightarrow \nabla C_{reg}(w) &= \nabla C(w) + \lambda \norm{w}^2 \\
	&\approx -2X[n]e[n] + \lambda \norm{w}^2
\end{align*}
Therefore, the update equation is
\[\hat{w}[n+1] = \hat{w}[n] - \half \mu \nabla C_{reg}(w) = \hat{w}[n] + \mu\left(X[n]e[n] - \frac{\lambda}{2} \norm{w}^2 \right)\]

\item We have
\begin{align*}
	a_x[k] &= \frac{3}{4} + \frac{1}{4}(-1)^k \\
	\Rightarrow a_x[k] &= \begin{cases}1 & k \text{ even} \\ \half & k \text{ odd}\end{cases}
\end{align*}
For $L=3$
\[R_x = \vect{a_x[0] & a_x[1] & a_x[2] \\ a_x[1] & a_x[0] & a_x[1] \\ a_x[2] & a_x[1] & a_x[0]} = \vect{1 & \half & 1 \\ \half & 1 & \half \\ 1 & \half & 1}\]
For one step prediction, $d[n] = x[n+1]$, therefore
\[R_{xd} = \vec{a_x[1] \\ a_x[2] \\ a_x[3]} = \vect{\half \\ 1 \\ \half}\]
Wiener filter of $x$ is $w_{opt} = R_x^{-1} R_{xd}$. However, $R_x$ is singular. We can use the pseudo-inverse of $R_x$ instead, i.e. 
\[R_x^\dagger = \vect{\frac{1}{3} & -\frac{1}{3} & \frac{1}{3} \\ -\frac{1}{3} & \frac{4}{3} & -\frac{1}{3} \\ \frac{1}{3} & -\frac{1}{3} & \frac{1}{3}}\]
\[w_p = R_x^\dagger R_{xd} = \vect{0 \\ 1 \\ 0}\]
With $\lambda = 0.1$
\[R_x + \lambda I = \vect{1.1 & 0.5 & 1 \\ 0.5 & 1.1 & 0.5 \\ 1 & 0.5 & 1.1}\]
\[w_l = (R_x + \lambda I)^{-1} R_{xd} \approx \vect{0.0276 \\ 0.8840 \\ 0.0276}\]
\end{enumerate}